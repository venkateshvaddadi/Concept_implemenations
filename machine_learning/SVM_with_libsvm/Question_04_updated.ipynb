{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libsvm.svm import *\n",
    "from libsvm.svmutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_data(data_path):\n",
    "    image_file_paths=os.listdir(data_path)\n",
    "    X=[]\n",
    "    labels=[]\n",
    "    \n",
    "    print('image data loading from ',data_path)\n",
    "    for i in image_file_paths:\n",
    "        individual_image_path=data_path+\"/\"+i\n",
    "        #print(i.split('.')[1])\n",
    "        if(i.split('.')[1]=='happy'):\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(-1)\n",
    "        individual_image_file = Image.open(individual_image_path)\n",
    "        individual_image_file=np.array(individual_image_file,dtype='float64')\n",
    "        individual_image_file=np.reshape(individual_image_file,-1)\n",
    "        X.append(individual_image_file)\n",
    "    \n",
    "    # made into single numpy array of N*size_of_image\n",
    "    X=np.array(X)\n",
    "    labels=np.array(labels)\n",
    "    \n",
    "    print('image data loaded.')\n",
    "    return X,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image data loading from  Data/emotion_classification/train\n",
      "image data loaded.\n",
      "image data loading from  Data/emotion_classification/test\n",
      "image data loaded.\n"
     ]
    }
   ],
   "source": [
    "train_data_path='Data/emotion_classification/train'\n",
    "train_X,train_labels=load_image_data(train_data_path)\n",
    "train_N=train_X.shape[0]\n",
    "train_D=train_X.shape[1]\n",
    "\n",
    "\n",
    "test_data_path='Data/emotion_classification/test'\n",
    "test_X,test_labels=load_image_data(test_data_path)\n",
    "test_N=test_X.shape[0]\n",
    "test_D=test_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 10201)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data=np.vstack([train_X,test_X])\n",
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 8)\n",
      "(20, 8)\n",
      "(10, 8)\n"
     ]
    }
   ],
   "source": [
    "K=8\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=K)\n",
    "projected_full_data = pca.fit_transform(full_data)\n",
    "print(projected_full_data[0:20,:].shape)\n",
    "\n",
    "projected_trained_data=projected_full_data[0:20,:]\n",
    "projected_tested_data=projected_full_data[20:30,:]\n",
    "\n",
    "print(projected_trained_data.shape)\n",
    "print(projected_tested_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training:\n",
      "Accuracy = 100% (20/20) (classification)\n",
      "For testing:\n",
      "Accuracy = 90% (9/10) (classification)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0],\n",
       " (90.0, 0.4, 0.6666666666666666),\n",
       " [[6.320250273694218],\n",
       "  [0.9277095814932129],\n",
       "  [-7.292812055407042],\n",
       "  [-0.02590085980697221],\n",
       "  [-1.6959412675825565],\n",
       "  [17.7548548188702],\n",
       "  [-0.18332828890534703],\n",
       "  [0.5357312509963957],\n",
       "  [5.118488849453515],\n",
       "  [-7.599157487128016]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = svm_problem(train_labels,projected_trained_data)\n",
    "\n",
    "param = svm_parameter()\n",
    "param.kernel_type = LINEAR\n",
    "param.C = 0.000010\n",
    "param.eps=0.5\n",
    "\n",
    "m = svm_train(prob, param)\n",
    "\n",
    "print(\"For training:\")\n",
    "svm_predict(train_labels,projected_trained_data,m)\n",
    "\n",
    "print(\"For testing:\")\n",
    "svm_predict(test_labels,projected_tested_data,m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_cusomized(train_data,labels,C,epsilon,kernel_type):\n",
    "    prob = svm_problem(labels,train_data)\n",
    "\n",
    "    param = svm_parameter()\n",
    "    param.C = C\n",
    "    param.eps=epsilon\n",
    "    \n",
    "    if(kernel_type=='LINEAR'):\n",
    "        param.kernel_type = LINEAR\n",
    "    elif(kernel_type=='POLY'):\n",
    "        param.kernel_type = POLY\n",
    "    elif(kernel_type=='RBF'):\n",
    "        param.kernel_type = RBF\n",
    "    elif(kernel_type=='SIGMOID'):\n",
    "        param.kernel_type = SIGMOID\n",
    "    \n",
    "    m = svm_train(prob, param)\n",
    "\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR KERNEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training:\n",
      "Accuracy = 100% (20/20) (classification)\n",
      "For testing:\n",
      "Accuracy = 90% (9/10) (classification)\n"
     ]
    }
   ],
   "source": [
    "m=svm_cusomized(projected_trained_data,train_labels,C=0.000010,epsilon=0.5,kernel_type='LINEAR')\n",
    "\n",
    "print(\"For training:\")\n",
    "svm_predict(train_labels,projected_trained_data,m)\n",
    "\n",
    "print(\"For testing:\")\n",
    "predicted_labels=svm_predict(test_labels,projected_tested_data,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POLYNOMIAL KERNEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training:\n",
      "Accuracy = 100% (20/20) (classification)\n",
      "For testing:\n",
      "Accuracy = 60% (6/10) (classification)\n"
     ]
    }
   ],
   "source": [
    "m=svm_cusomized(projected_trained_data,train_labels,C=0.000010,epsilon=0.5,kernel_type='POLY')\n",
    "\n",
    "print(\"For training:\")\n",
    "svm_predict(train_labels,projected_trained_data,m)\n",
    "\n",
    "print(\"For testing:\")\n",
    "predicted_labels=svm_predict(test_labels,projected_tested_data,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF-KERNEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training:\n",
      "Accuracy = 100% (20/20) (classification)\n",
      "For testing:\n",
      "Accuracy = 40% (4/10) (classification)\n"
     ]
    }
   ],
   "source": [
    "m=svm_cusomized(projected_trained_data,train_labels,C=1,epsilon=0.5,kernel_type='RBF')\n",
    "\n",
    "print(\"For training:\")\n",
    "svm_predict(train_labels,projected_trained_data,m)\n",
    "\n",
    "print(\"For testing:\")\n",
    "predicted_labels=svm_predict(test_labels,projected_tested_data,m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIGMOID-KERNEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training:\n",
      "Accuracy = 70% (14/20) (classification)\n",
      "For testing:\n",
      "Accuracy = 50% (5/10) (classification)\n"
     ]
    }
   ],
   "source": [
    "m=svm_cusomized(projected_trained_data,train_labels,C=10,epsilon=0.5,kernel_type='SIGMOID')\n",
    "\n",
    "print(\"For training:\")\n",
    "svm_predict(train_labels,projected_trained_data,m)\n",
    "\n",
    "print(\"For testing:\")\n",
    "predicted_labels=svm_predict(test_labels,projected_tested_data,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50.0, 2.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print(predicted_labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear kernel is performing is giving good accuracy when compare with other kernels. After linear kernels, polynomial kernels are given a better accuracy.\n",
    "\n",
    "The following table explains the performance of the various kernels on the SVM Model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  \n",
    "<tr>\n",
    "    <td>KERNEL</td>\n",
    "    <td>Training Accuracy</td>\n",
    "    <td>Testing Accuracy</td>\n",
    "</tr>  \n",
    "  \n",
    "<tr>\n",
    "    <td>LINEAR-KERNEL</td>\n",
    "    <td>100%</td>\n",
    "    <td>90%</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>POLYNOMIAL-KERNEL</td>\n",
    "<td>100%</td>\n",
    "<td>70%</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>RBF-KERNEL</td>\n",
    "<td>100%</td>\n",
    "<td>40%</td>\n",
    "</tr>\n",
    "\n",
    "<tr>\n",
    "<td>SIGMOID-KERNEL</td>\n",
    "<td>70%</td>\n",
    "<td>50%</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>How does the performance change as a function of K ?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def projected_data(full_data,K):\n",
    "    pca = PCA(n_components=K)\n",
    "    projected_full_data = pca.fit_transform(full_data)\n",
    "    print(projected_full_data[0:20,:].shape)\n",
    "\n",
    "    projected_trained_data=projected_full_data[0:20,:]\n",
    "    projected_tested_data=projected_full_data[20:30,:]\n",
    "\n",
    "    #print(projected_trained_data.shape)\n",
    "    #print(projected_tested_data.shape)\n",
    "    \n",
    "    return projected_trained_data,projected_tested_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_experiment(training_data,testing_data,kernel_type):\n",
    "    \n",
    "    train_X,train_labels=training_data\n",
    "    test_X,test_labels=testing_data\n",
    "\n",
    "    statastics=[]\n",
    "    C=0.000001\n",
    "    for i in range(14):\n",
    "        epsilon=0.5\n",
    "        m=svm_cusomized(train_X,train_labels,C,epsilon,kernel_type)\n",
    "\n",
    "        #print(\"For training:\")\n",
    "        traing_accuracy=svm_predict(train_labels,train_X,m)[1][0]\n",
    "        #print(\"For testing:\")\n",
    "        testing_accuracy=svm_predict(test_labels,test_X,m)[1][0]\n",
    "\n",
    "\n",
    "        #print([kernel_type,C,epsilon,traing_accuracy,testing_accuracy,m.get_nr_sv()])\n",
    "\n",
    "        statastics.append([kernel_type,C,epsilon,traing_accuracy,testing_accuracy,m.get_nr_sv()])\n",
    "        C=C*10\n",
    "\n",
    "    for i in statastics:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for K in range(1,11):\n",
    "    print(K)\n",
    "    projected_trained_data,projected_tested_data=projected_data(full_data,K)\n",
    "    training_data=(projected_trained_data,train_labels)\n",
    "    testing_data=(projected_tested_data,test_labels)\n",
    "    svm_experiment(training_data,testing_data,'LINEAR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the results of various experiments of SVM on the different dimenstional data with different kernel functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<table>\n",
    "<tr><td>K</td><td>Kernel</td><td>C</td><td>Epsilon</td><td>Traing Accuracy</td><td>Testing Accuracy</td><td>NoSupport Vectors</td></tr>\n",
    "\n",
    "<tr><td>1</td><td>'LINEAR'</td><td> 100.0</td><td> 0.5</td><td> 50.0</td><td> 60.0</td><td> 7</td></tr>\n",
    "<tr><td>2</td><td>'LINEAR'</td><td> 10.0</td><td> 0.5</td><td> 65.0</td><td> 50.0</td><td> 12</td></tr>\n",
    "<tr><td>3</td><td>'LINEAR'</td><td> 1.0</td><td> 0.5</td><td> 65.0</td><td> 50.0</td><td> 18</td></tr>\n",
    "<tr><td>4</td><td>'LINEAR'</td><td> 1.0</td><td> 0.5</td><td> 50.0</td><td> 60.0</td><td> 18</td></tr>\n",
    "<tr><td>5</td><td>'LINEAR'</td><td>0.0001</td><td> 0.5</td><td> 65.0</td><td> 70.0</td><td> 17</td></tr>\n",
    "<tr><td>6</td><td>'LINEAR'</td><td> 0.001</td><td> 0.5</td><td> 90.0</td><td> 90.0</td><td> 9</td></tr>\n",
    "<tr><td>7</td><td>'LINEAR'</td><td> 1.0</td><td> 0.5</td><td> 90.0</td><td> 90.0</td><td> 10</td></tr>\n",
    "<tr><td>8</td><td>'LINEAR'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 90.0</td><td> 10</td></tr>\n",
    "<tr><td>9</td><td>'LINEAR'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 90.0</td><td> 10</td></tr>\n",
    "<tr><td>10</td><td>'LINEAR'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 90.0</td><td> 11</td></tr>\n",
    "\n",
    "\n",
    "</table>\n",
    "<table>\n",
    "<tr><td>K</td><td>Kernel</td><td>C</td><td>Epsilon</td><td>Traing Accuracy</td><td>Testing Accuracy</td><td>NoSupport Vectors</td></tr>\n",
    "\n",
    "<tr><td>1</td><td>'POLY'</td><td> 0.1</td><td> 0.5</td><td> 55.00000000000001</td><td> 40.0</td><td> 7</td></tr>\n",
    "<tr><td>2</td><td>'POLY'</td><td> 1.0</td><td> 0.5</td><td> 50.0</td><td> 70.0</td><td> 7</td></tr>\n",
    "<tr><td>3</td><td>'POLY'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 50.0</td><td> 11</td></tr>\n",
    "<tr><td>4</td><td>'POLY'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 60.0</td><td> 13</td></tr>\n",
    "<tr><td>5</td><td>'POLY'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 50.0</td><td> 16</td></tr>\n",
    "<tr><td>6</td><td>'POLY'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 70.0</td><td> 13</td></tr>\n",
    "<tr><td>7</td><td>'POLY'</td><td> 0.1</td><td> 0.5</td><td> 100.0</td><td> 70.0</td><td> 15</td></tr>\n",
    "<tr><td>8</td><td>'POLY'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 50.0</td><td> 15</td></tr>\n",
    "<tr><td>9</td><td>'POLY'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 50.0</td><td> 15</td></tr>\n",
    "<tr><td>10</td><td>'POLY'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 50.0</td><td> 15</td></tr>\n",
    "</table>\n",
    "<table>\n",
    "\n",
    "<tr><td>K</td><td>Kernel</td><td>C</td><td>Epsilon</td><td>Traing Accuracy</td><td>Testing Accuracy</td><td>NoSupport Vectors</td></tr>\n",
    "\n",
    "<tr><td>1</td><td>'SIGMOID'</td><td> 1.0</td><td> 0.5</td><td> 55.00000000000001</td><td> 40.0</td><td> 18</td></tr>\n",
    "<tr><td>2</td><td>'SIGMOID'</td><td> 1.0</td><td> 0.5</td><td> 60.0</td><td> 40.0</td><td> 10</td></tr>\n",
    "<tr><td>3</td><td>'SIGMOID'</td><td> 1.0</td><td> 0.5</td><td> 55.00000000000001</td><td> 60.0</td><td> 13</td></tr>\n",
    "<tr><td>4</td><td>'SIGMOID'</td><td> 1.0</td><td> 0.5</td><td> 50.0</td><td> 60.0</td><td> 12</td></tr>\n",
    "<tr><td>5</td><td>'SIGMOID'</td><td> 1.0</td><td> 0.5</td><td> 65.0</td><td> 60.0</td><td> 10</td></tr>\n",
    "<tr><td>6</td><td>'SIGMOID'</td><td> 1.0</td><td> 0.5</td><td> 60.0</td><td> 80.0</td><td> 8</td></tr>\n",
    "<tr><td>7</td><td>'SIGMOID'</td><td> 1.0</td><td> 0.5</td><td> 60.0</td><td> 70.0</td><td> 10</td></tr>\n",
    "<tr><td>8</td><td>'SIGMOID'</td><td> 1.0</td><td> 0.5</td><td> 70.0</td><td> 50.0</td><td> 10</td></tr>\n",
    "<tr><td>9</td><td>'SIGMOID'</td><td> 1.0</td><td> 0.5</td><td> 70.0</td><td> 60.0</td><td> 10</td></tr>\n",
    "<tr><td>10</td><td>'SIGMOID'</td><td> 1.0</td><td> 0.5</td><td> 70.0</td><td> 60.0</td><td> 10</td></tr>\n",
    "\n",
    "</table>\n",
    "<table>\n",
    "\n",
    "\n",
    "<tr><td>K</td><td>Kernel</td><td>C</td><td>Epsilon</td><td>Traing Accuracy</td><td>Testing Accuracy</td><td>NoSupport Vectors</td></tr>\n",
    "\n",
    "<tr><td>1</td><td>'RBF'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 40.0</td><td> 20</td></tr>\n",
    "<tr><td>2</td><td>'RBF'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 40.0</td><td> 20</td></tr>\n",
    "<tr><td>3</td><td>'RBF'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 40.0</td><td> 20</td></tr>\n",
    "<tr><td>4</td><td>'RBF'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 40.0</td><td> 20</td></tr>\n",
    "<tr><td>5</td><td>'RBF'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 40.0</td><td> 20</td></tr>\n",
    "<tr><td>6</td><td>'RBF'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 40.0</td><td> 20</td></tr>\n",
    "<tr><td>7</td><td>'RBF'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 40.0</td><td> 20</td></tr>\n",
    "<tr><td>8</td><td>'RBF'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 40.0</td><td> 20</td></tr>\n",
    "<tr><td>9</td><td>'RBF'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 40.0</td><td> 20</td></tr>\n",
    "<tr><td>10</td><td>'RBF'</td><td> 1.0</td><td> 0.5</td><td> 100.0</td><td> 40.0</td><td> 20</td></tr>\n",
    "<table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results, we see the following obervations.\n",
    "\n",
    "initially, with k value, the model accuaracy is also increased.\n",
    "\n",
    "if dimension(K) of the data is more means, it also represents more variance of the data.\n",
    "\n",
    "But, after particular K (7 or more than 7 here) most of the variance of the data was already represented with that particualr K. Therefore, after particular K the model accuracy do not get effected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the assignment_01, the following things are noticed.\n",
    "\n",
    "SVM with linear kernel performing better than LDA with same value of the K.\n",
    "\n",
    "Following are some of the results.\n",
    "\n",
    "<table>\n",
    "    <tr><td>K</td><td>Testing Accuracy</td></tr>\n",
    "    <tr><td>5</td><td>50</td></tr>\n",
    "    <tr><td>10</td><td>60</td></tr>\n",
    "    <tr><td>15</td><td>70</td></tr>\n",
    "    <tr><td>20</td><td>80</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <p style=\"background-color: #ffe5e2; \">\n",
    "LDA is a supervised dimensionality reduction technique that minimizes the intra class variance and maximizes the inter class variance in the lower dimension space. SVM finds an optimal hyperplane in some non-linear higher dimension space using kernel technique.\n",
    "    </p>\n",
    "\n",
    "<p style=\"background-color: #ffe5e2; \">\n",
    "LDA is analytical solution.\n",
    "But, SVM is iterative solution.\n",
    "</p >\n",
    "    \n",
    "<p style=\"background-color: #ffe5e2; \">\n",
    "LDA is can handle the multiple classes simultaneously. \n",
    "SVM is two class classifier. Therefore, it handles the multi-class classification as as multiple one vs others  problems.\n",
    "</p>\n",
    "\n",
    "<p style=\"background-color: #ffe5e2; \">\n",
    "In the LDA we use using the co-variance matrix of whole data and same class.Therefore, we use the all data.\n",
    "In the SVM, we use the some subset of the data to model, it is called support vectors. The SVM model is optimized on support vectors. These support vectors are only the margin of the classifier.\n",
    "</p>\n",
    "\n",
    "\n",
    "<p style=\"background-color: #ffe5e2; \">\n",
    "SVM is very sensitive to data. The small variations in the data leads to big changes in the model.\n",
    "</p>\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
